#!/usr/bin/env python
# -*- coding: utf-8 -*-
# authorï¼šzenghui time:2020/6/11

from Augmentor.Pipeline import Pipeline
from PIL import Image
import random
import os
import uuid
from tqdm import tqdm
from concurrent.futures import ThreadPoolExecutor
import copy


class Pipeline_speckle(Pipeline):

    def __init__(self, source_directory=None, output_directory="output", save_format=None):
       super(Pipeline_speckle,self).__init__(source_directory=source_directory, output_directory=output_directory, save_format=save_format)
       self.source_directory=source_directory

       self.train_txt_directory = os.path.dirname(self.source_directory) + '/train.txt'
       self.valid_txt_directory = os.path.dirname(self.source_directory) + '/valid.txt'


    def sample(self, n, multi_threaded=True,data_ratio=0.8):
        """
        Generate :attr:`n` number of samples from the current pipeline.

        This function samples from the pipeline, using the original images
        defined during instantiation. All images generated by the pipeline
        are by default stored in an ``output`` directory, relative to the
        path defined during the pipeline's instantiation.

        By default, Augmentor will use multi-threading to increase the speed
        of processing the images. However, this may slow down some
        operations if the images are very small. Set :attr:`multi_threaded`
        to ``False`` if slowdown is experienced.

        :param n: The number of new samples to produce.
        :type n: Integer
        :param multi_threaded: Whether to use multi-threading to process the
         images. Defaults to ``True``.
        :type multi_threaded: Boolean
        :return: None
        """
        augmentor_images = list(range(n))
        self.data_ratio = data_ratio
        if len(self.augmentor_images) == 0:
            raise IndexError("There are no images in the pipeline. "
                             "Add a directory using add_directory(), "
                             "pointing it to a directory containing images.")

        if len(self.operations) == 0:
            raise IndexError("There are no operations associated with this pipeline.")

        if n == 0:
            augmentor_images = self.augmentor_images
        else:
            for i in range(n):
                augmentor_images[i] = copy.deepcopy(random.choice(self.augmentor_images))

        train_image_num = round(data_ratio* n)
        image_num = 0
        for augmentor_image in augmentor_images:
            image_name = os.path.basename(augmentor_image.image_path).split('.')[0]
            image_format = os.path.basename(augmentor_image.image_path).split('.')[1]
            UUID=uuid.uuid4()
            image_name = image_name+'-'+str(UUID)
            if image_num<round(train_image_num):
                txt_directory=self.train_txt_directory
            else:
                txt_directory = self.valid_txt_directory
            f = open(txt_directory,'a')
            save_directory = os.path.join(augmentor_image.output_directory, image_name)
            augmentor_image.new_name = image_name
            f.write(save_directory  + '\t' + '16' + '\t' + image_format + '\n')
            f.close()
            image_num=image_num+1

        if multi_threaded:
            # TODO: Restore the functionality (appearance of progress bar) from the pre-multi-thread code above.
            with tqdm(total=len(augmentor_images), desc="Executing Pipeline", unit=" Samples") as progress_bar:
                with ThreadPoolExecutor(max_workers=None) as executor:
                    for result in executor.map(self, augmentor_images):
                        progress_bar.set_description("Processing %s" % result)
                        progress_bar.update(1)
        else:
            with tqdm(total=len(augmentor_images), desc="Executing Pipeline", unit=" Samples") as progress_bar:
                for augmentor_image in augmentor_images:
                    self._execute(augmentor_image)
                    progress_bar.set_description("Processing %s" % os.path.basename(augmentor_image.image_path))
                    progress_bar.update(1)


    def _execute(self, augmentor_image,save_to_disk=True, multi_threaded=True,):
        """
        Private method. Used to pass an image through the current pipeline,
        and return the SIM images, and  write image directories, wave vectors, phi into a json file  .

        The returned image can then either be saved to disk or simply passed
        back to the user. Currently this is fixed to True, as Augmentor
        has only been implemented to save to disk at present.

        :param augmentor_image: The image to pass through the pipeline.
        :param save_to_disk: Whether to save the image to disk. Currently
         fixed to true.
        :type augmentor_image: :class:`ImageUtilities.AugmentorImage`
        :type save_to_disk: Boolean
        :return: The augmented image.
        """

        images = []

        if augmentor_image.image_path is not None:
            images.append(Image.open(augmentor_image.image_path))

        # What if they are array data?
        if augmentor_image.pil_images is not None:
            images.append(augmentor_image.pil_images)

        if augmentor_image.ground_truth is not None:
            if isinstance(augmentor_image.ground_truth, list):
                for image in augmentor_image.ground_truth:
                    images.append(Image.open(image))
            else:
                images.append(Image.open(augmentor_image.ground_truth))

        for operation in self.operations:
            r = round(random.uniform(0, 1), 1)
            if r <= operation.probability:
                images = operation.perform_operation(images)


            # file_name = os.path.basename(augmentor_image.image_path).split('.')[0]

            file_name = augmentor_image.new_name
            image_format = os.path.basename(augmentor_image.image_path).split('.')[1]

            try:
                for i in range(len(images)):
                    if i == 0:
                        save_name =  file_name\
                                    +"_SR_"\
                                    +'.' + image_format
                        images[i].save(os.path.join(augmentor_image.output_directory, save_name))
                    elif i == 1:
                        save_name = file_name\
                                    +"_LR_"\
                                    +'.'+ image_format
                        images[i].save(os.path.join(augmentor_image.output_directory, save_name))
                    else:
                        save_name = file_name\
                                    +"_Speckle_SIM_data(" \
                                    +str(i - 1) \
                                    +")_" \
                                    +'.' + image_format
                        images[i].save(os.path.join(augmentor_image.output_directory, save_name))

            except IOError as e:
                print("Error writing %s, %s. Change save_format to PNG?" % ('LR', e.message))
                print("You can change the save format using the set_save_format(save_format) function.")
                print("By passing save_format=\"auto\", Augmentor can save in the correct format automatically.")


        # TODO: Fix this really strange behaviour.
        # As a workaround, we can pass the same back and basically
        # ignore the multi_threaded parameter completely for now.
        # if multi_threaded:
        #   return os.path.basename(augmentor_image.image_path)
        # else:
        #   return images[0]  # Here we return only the first image for the generators.

        # return images[0]  # old method.
        return images[0]